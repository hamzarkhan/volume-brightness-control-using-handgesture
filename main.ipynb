{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2256159-d93d-4c50-a1f1-417f7bdde170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from math import hypot\n",
    "import screen_brightness_control as sbc\n",
    "import numpy as np\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "\n",
    "# Initialize Mediapipe Hands\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    min_detection_confidence=0.75,\n",
    "    min_tracking_confidence=0.75,\n",
    "    max_num_hands=2,\n",
    ")\n",
    "Draw = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize Pycaw for Volume Control\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(\n",
    "    IAudioEndpointVolume._iid_, CLSCTX_ALL, None\n",
    ")\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "# Capture video from webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read video frame by frame\n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)  # Flip image\n",
    "    frameRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "\n",
    "    # Process the RGB image\n",
    "    process = hands.process(frameRGB)\n",
    "\n",
    "    landmarkList = []\n",
    "    if process.multi_hand_landmarks:\n",
    "        for hand_id, handlm in enumerate(process.multi_hand_landmarks):\n",
    "            hand_type = \"Left\" if hand_id == 0 else \"Right\"  # Assuming left hand is first\n",
    "            for _id, landmarks in enumerate(handlm.landmark):\n",
    "                height, width, color_channels = frame.shape\n",
    "                x, y = int(landmarks.x * width), int(landmarks.y * height)\n",
    "                landmarkList.append([hand_type, _id, x, y])\n",
    "\n",
    "            # Draw landmarks\n",
    "            Draw.draw_landmarks(frame, handlm, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Handle brightness and volume control\n",
    "    if landmarkList != []:\n",
    "        for hand in [\"Left\", \"Right\"]:\n",
    "            hand_points = [lm for lm in landmarkList if lm[0] == hand]\n",
    "            if hand_points:\n",
    "                x_thumb, y_thumb = hand_points[4][2], hand_points[4][3]  # Thumb tip\n",
    "                x_index, y_index = hand_points[8][2], hand_points[8][3]  # Index finger tip\n",
    "\n",
    "                # Draw circles and line\n",
    "                cv2.circle(frame, (x_thumb, y_thumb), 7, (0, 255, 0), cv2.FILLED)\n",
    "                cv2.circle(frame, (x_index, y_index), 7, (0, 255, 0), cv2.FILLED)\n",
    "                cv2.line(frame, (x_thumb, y_thumb), (x_index, y_index), (0, 255, 0), 3)\n",
    "\n",
    "                # Calculate distance\n",
    "                length = hypot(x_index - x_thumb, y_index - y_thumb)\n",
    "\n",
    "                if hand == \"Right\":\n",
    "                    # Brightness control (Hand range: 15-220, Brightness range: 0-100)\n",
    "                    b_level = np.interp(length, [15, 220], [0, 100])\n",
    "                    sbc.set_brightness(int(b_level))\n",
    "                elif hand == \"Left\":\n",
    "                    # Volume control (Hand range: 15-220, Volume range: -65.25 to 0)\n",
    "                    vol_level = np.interp(length, [15, 220], [-65.25, 0])\n",
    "                    volume.SetMasterVolumeLevel(vol_level, None)\n",
    "\n",
    "    # Display Video and Exit on 'q'\n",
    "    cv2.imshow(\"Image\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b6e85f3-b465-4b04-9192-c344d049d336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t.ipynb_checkpoints/\n",
      "\tmain.ipynb\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e83d49-484d-49ba-9ef0-5986a3d19f27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
